#!/usr/bin/env python3
"""
Test script for bronze â†’ silver â†’ gold data pipeline
"""
import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data.bronze import load_data
from src.data.silver import DataPipeline
from src.data.gold import DataManager

def main():
    print("ğŸ”„ Testing Bronze â†’ Silver â†’ Gold Pipeline")
    print("=" * 50)
    
    # Bronze: Load raw data
    print("\nğŸ“¥ BRONZE: Loading raw data...")
    train_raw, test_raw = load_data()
    print(f"âœ… Train shape: {train_raw.shape}")
    print(f"âœ… Test shape: {test_raw.shape}")
    print(f"âœ… Columns: {list(train_raw.columns)}")
    
    # Silver: Basic preprocessing
    print("\nâš™ï¸  SILVER: Basic preprocessing...")
    db_path = os.getenv('DB_PATH', '/home/wsl/dev/my-study/ml/solid-ml-stack-s5e7/data/kaggle_datasets.duckdb')
    pipeline = DataPipeline(db_path)
    train_clean = pipeline.preprocess(train_raw)
    test_clean = pipeline.preprocess(test_raw)
    print(f"âœ… Train clean shape: {train_clean.shape}")
    print(f"âœ… Test clean shape: {test_clean.shape}")
    print(f"âœ… Dtypes: {dict(train_clean.dtypes)}")
    
    # Gold: Feature engineering  
    print("\nâœ¨ GOLD: Feature engineering...")
    dm = DataManager()
    X_train, X_test = dm.get_data()
    y_train = train_clean['Personality']
    print(f"âœ… X_train shape: {X_train.shape}")
    print(f"âœ… y_train shape: {y_train.shape}")
    print(f"âœ… X_test shape: {X_test.shape}")
    print(f"âœ… Feature columns: {list(X_train.columns)}")
    
    # Summary
    print("\nğŸ“Š PIPELINE SUMMARY")
    print("=" * 50)
    print(f"Raw â†’ Clean: {train_raw.shape} â†’ {train_clean.shape}")
    print(f"Clean â†’ Features: {train_clean.shape} â†’ {X_train.shape}")
    print(f"Target distribution: {y_train.value_counts().to_dict()}")
    print("\nâœ… Pipeline test completed successfully!")

if __name__ == "__main__":
    main()