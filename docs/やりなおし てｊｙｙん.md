### Kaggle プロジェクトを「再開・やり直し」するときの大きな流れ

（全体像 → 各フェーズで“何を完了したら次に進むか”が分かるように整理）

| フェーズ                          | ゴール                                     | 主要アクション                                                                                                                 | 完了判定                                     |
| ----------------------------- | --------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | ---------------------------------------- |
| **0. 現状凍結 & 安全確保**            | いつでもロールバックできる状態を作る                      | \* 既存 `solid-ml-stack-s5e7` を別ブランチ／ZIPでアーカイブ<br>\* 今の公開 LB 用 submit.csv と notebook をバックアップ                              | ✅ アーカイブがクラウド or 別 HDD に置かれ、現状コードは完全に触らない |
| **1. クリーン・スケルトン生成**           | シンプルな骨格だけの新リポジトリ `kaggle-ml-clean` を作る  | \* テンプレ構成（`src/`,`config/`,`data/` …）を空ファイルでコミット<br>\* `pyproject.toml` と `Makefile` を用意                                | ✅ `make test` が通る最小環境が動く                 |
| **2. 開発基盤セットアップ**             | 品質と再現性を支える共通インフラを整備                     | \* pre-commit（black, flake8, mypy）<br>\* pytest 空テスト<br>\* VSCode DevContainer or Conda env<br>\* タイムトラッカー & Webhook 雛形 | ✅ `git push` → CI が green になる            |
| **3. データ層確定（DuckDB 3 段階）**    | Raw→Preprocessed→Engineered のテーブルを出力できる | \* `src/data.py` を実装し<br>  `make setup-data` で CSV→DuckDB ロード<br>\* クリーニング関数（欠損補完など）を fold 非依存で実装                       | ✅ `SELECT count(*)` が想定通り／統計ログが JSON に残る |
| **4. ベースライン再現**               | 軽量 LightGBM が CV 0.xx（例 0.975） を出す      | \* 乱数固定 StratifiedKFold で学習<br>\* `src/validation.py` で CV ログを出力                                                        | ✅ CV と 公開 LB の乖離 ≦ 0.01                  |
| **5. 特徴量リファクタリング**            | 「少数精鋭」の Feature セット確立                   | \* 既存コードから有効値上位 20〜30 種を抽出<br>\* ターゲットエンコーディングを **fold 内** に移植<br>\* 不要な冗長クラス・関数を削除                                     | ✅ 各特徴量の SHAP/Imp が可視化され“死に特徴量”が < 10 %   |
| **6. 検証戦略ロック**                | 「Trust Your CV」を実現                      | \* GroupKFold 等が必要ないか点検<br>\* 毎 run 同じスコアになることを確認                                                                       | ✅ 3 連続実行で CV σ ≦ 0.002                   |
| **7. ハイパラ最適化**                | 単体モデルを限界までチューニング                        | \* Optuna で LGBM → XGB → Cat を順番に bayes search<br>\* 上位 2〜3 モデルを選定                                                      | ✅ 単体最高 CV が ベースライン +0.3pt 以上             |
| **8. アンサンブル & submit パイプライン** | 汎化性能の最終ブースト                             | \* Seed 平均 → 重み付き平均<br>\* （必要なら）簡易 Stacking（LR）                                                                         | ✅ CV best & 公開 LB best が揃う               |
| **9. 運用 & 監視**                | 長時間実験でも安心運用                             | \* 実行時間ログ → 平均/予測終了時刻を表示<br>\* Discord Webhook 通知有効化                                                                    | ✅ 夜間ジョブが朝に自動で結果報告                        |
| **10. ドキュメント & 振り返り**         | いつでも再現できる状態を完成                          | \* README に「環境構築 → 学習 → 提出」手順を記載<br>\* 改善ログ・CV 推移を Markdown で残す                                                         | ✅ 新メンバーが README だけで submit 可能            |

---

#### 時間感覚の目安

* **フェーズ 0–3** : ½ 日
* **フェーズ 4–6** : 1 〜 2 日
* **フェーズ 7–8** : 2 〜 3 日（Optuna 回しながら並行作業）
* **フェーズ 9–10** : ½ 日

合計 **約 4 〜 6 日** で、既存コードを抱えたままより **大幅に見通しの良い基盤** が完成します。
あとは **CV→公開 LB→非公開 LB の差分を小さく保つこと** に集中すれば、銅メダル圏（上位 10 %）が射程に入ります。
