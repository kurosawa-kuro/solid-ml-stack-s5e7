以下に **Playground Series S5E7（Introvert vs Extrovert分類）で実施すべき前処理チェックリスト（優先度付き）** をまとめます。英語圏のKaggle Notebook／Discussion／Blog等も調査し、日本語で要約しています。必要なら後続でリポジトリ（`solid-ml-stack-s5e7`）に組み込みやすいコードスニペット／Pipeline雛形を作成しますのでお申し付けください。

---

## 0. データ概要再確認（列・型・由来）

本コンペのデータは「Extrovert vs Introvert Behavior / Personality Traits」系の行動・心理指標（例: `Time_spent_Alone`, `Social_event_attendance`, `Friends_circle_size`, `Drained_after_socializing`, `Going_outside`, `Stage_fear`, `Post_frequency`）から生成され、ターゲットは `Personality`（Introvert/Extrovert）。Playground用に**元データを元に深層学習モデル等から生成されたシンセティックデータ**である旨が案内されており、元データとの分布差や軽度なラベルノイズの可能性を念頭に置く必要があります。 ([opendatabay.com][1], [Medium][2], [Kaggle][3])

---

## 1. 前処理優先度マトリクス

| 優先度        | 目的            | 推奨アクション（概要）                                                                 |
| ---------- | ------------- | --------------------------------------------------------------------------- |
| **必須**     | データ破損防止・リーク防止 | 型明示、欠損確認→適切補完、バイナリ標準化、順序尺度定義、Fold内変換、 Stratified K-Fold。                    |
| **強推奨**    | モデル性能・再現性     | 外れ値クリーニング／ウィンズライジング、スケーリング（線形/距離系モデル）、カテゴリ頻度/ターゲット統計派生（ツリーモデル以外）、カテゴリ結合数制御。 |
| **実験価値あり** | 微差積み上げ        | 交互作用特徴（比率・差分）、頻度正規化（z-score / rankGauss）、ノイズ付与CVターゲットエンコ、半教師学習的擬似ラベル検証。     |

（以下で詳細。）

---

## 2. 必須ステップ（実装優先）

### 2.1 カラム型 & 値域バリデーション

* 明示的な dtype 設定（int/float/bool/category）で読み込み直後に検証。行動時間・回数系は非負、現実的上限（例: 24時間超の`Time_spent_Alone`は異常候補）など範囲チェックを追加。前処理前に「異常値→NaN化→補完or別特徴」とするガード。データ理解に時間を割くことが性能に直結。 ([Bradley Boehmke][4], [IBM][5])

### 2.2 欠損値処理（列タイプ別）

* Opendatabay記載どおり `Time_spent_Alone`, `Going_outside` など一部欠損が含まれうるため要補完。数値列: 平均/中央値/ロバスト統計（IQRトリム後中央値）を Fold 内で学習。カテゴリ列: 最頻値 or “Unknown” カテゴリ追加。 ([opendatabay.com][1], [UBC CS][6], [IBM][5])

### 2.3 バイナリYes/No正規化

* `Stage_fear`, `Drained_after_socializing` 等のYes/No系は統一表記（大文字小文字・スペル揺れ）→ {0,1} にバイナリマッピング。ロジスティック等数値前提モデルでは不可欠。 ([Medium][7], [IBM][5])

### 2.4 順序尺度エンコード定義

* 頻度系カテゴリ（例: `Social_event_attendance`, `Going_outside`, `Post_frequency`）は意味順序を定義して **OrdinalEncoding**。順序定義が曖昧なら頻度に基づく自動順序（countベース）か、One-Hotへフォールバック。スケール歪みを避けるため定義を1カ所に集中管理。 ([scikit-learn.org][8], [Stack Overflow][9], [GeeksforGeeks][10])

### 2.5 学習・評価の情報リーク防止（Fold内変換）

* すべての統計量（欠損補完値、エンコードマッピング、スケーラーパラメータ）は **学習Foldのみ** で算出し、検証Fold・テストに適用。これを怠るとリークで過大評価になると多数の実装ガイド・Q\&Aで指摘。scikit-learn Pipeline + ColumnTransformer を使用して自動化推奨。 ([Medium][11], [UBC CS][6], [Stack Overflow][9])

### 2.6 Stratified K-Fold（クラス比率維持）

* 精度指標が Accuracy のため、クラス不均衡がFoldで崩れると分散が増える。Stratified K-Foldを使い常に Introvert/Extrovert 比率を維持することがロバスト評価に有効と複数解説で強調。 ([GeeksforGeeks][12], [MachineLearningMastery.com][13], [Medium][14])

### 2.7 （S5E7固有）元データとのマッチ／ラベルノイズ点検

* Kaggle Discussion では「元Extrovert vs Introvertデータとの行一致確認コード」やラベル差異を調べる投稿が報告されているため、公開元データと突き合わせて明らかなラベル反転行を特定→補正 or 重み調整を検討。 ([Kaggle][15], [opendatabay.com][1])

---

## 3. 強推奨ステップ（性能ブースト候補）

### 3.1 外れ値ハンドリング（Winsorize / Quantile Clip / RobustScaler）

* 行動時間や友人数などに極端値が混じると線形モデル・SVMで境界が歪む。IQRベースクリップまたは分位数(1%/99%)クリップ後にスケーリング。前処理講義や実践書でも推奨。 ([UBC CS][6], [Bradley Boehmke][4])

### 3.2 数値スケーリング（モデル依存）

* ロジスティック回帰・SVM・kNN等では標準化またはMinMaxが性能改善しやすい。ツリーベース（LGBM/XGB/CatBoost）はスケーリング不要だが外れ値除去は有効。 ([UBC CS][6], [GeeksforGeeks][12])

### 3.3 カテゴリエンコーディング多様化（モデル別）

* 少カテゴリ=One-Hot, 中カテゴリ=Ordinal, 高カテゴリ=頻度/Targetエンコなど状況で使い分けるのがモデル精度向上の鍵とチュートリアルで整理。 ([GeeksforGeeks][10], [Stack Overflow][9])

### 3.4 CatBoost活用（自動カテゴリ処理 & Ordered Target Stats）

* CatBoostはカテゴリを自動で処理し、Ordered Target Statisticsでリークを抑制しつつ高精度化する設計。手動One-Hotは品質低下を招く可能性があるため、CatBoost使用時は素のカテゴリ列を渡す実装を優先。 ([catboost.ai][16], [neptune.ai][17], [Kaggle][18])

### 3.5 Pipeline一元管理による再現性

* 異なる列に異なる変換（数値:欠損→スケール、カテゴリ:欠損→エンコード）を適用するPipelineを構築し、学習・推論で同一処理を保証。再現性がLeaderboard安定性（shake-up耐性）に寄与。 ([Medium][11], [UBC CS][6])

---

## 4. 実験ステップ（LB微差稼ぎ）

> 以下は「やってみる価値あり」。Fold平均+外部CVでぶれないものを採用。

### 4.1 比率・組合せ特徴

* 例: `Time_spent_Alone / (Time_spent_Alone + Social_event_attendance)` で「孤立度」指標、`Friends_circle_size / Social_event_attendance` で「1イベントあたり友人数」。一般的な特徴エンジニアリングで予測力向上余地。 ([Bradley Boehmke][4], [IBM][5])

### 4.2 頻度正規化 / RankGauss 変換

* 歪度が大きい行動指標はランクベース正規化で線形分離性を改善するケース。前処理・スケーリング解説で度々推奨。 ([UBC CS][6], [IBM][5])

### 4.3 Target Encoding（高カテゴリ時）+ ノイズ付与

* カテゴリ多数の場合、Fold内でターゲット平均を算出し微小ランダムノイズを重畳する手法はKaggleで一般的。エンコーディング総論記事でも紹介。リーク防止のためFold内計算厳守。 ([GeeksforGeeks][10], [Stack Overflow][9])

### 4.4 軽度ラベルノイズ補正重み

* 元データ突き合わせで怪しい行に低重みを付ける（sample\_weight）実験。ラベルノイズ議論スレ参照。 ([Kaggle][15], [opendatabay.com][1])

---

## 5. モデル別 前処理設定プリセット

### 5.1 Logistic Regression / Linear SVM

1. 欠損補完（数値:中央値, カテゴリ:最頻値）。
2. バイナリ0/1, 順序→Ordinal数値。
3. 数値スケール: StandardScaler or MinMax。
4. 交差検証は StratifiedKFold。
5. 可変: 外れ値クリップ。 ([Medium][11], [GeeksforGeeks][12], [Medium][7])

### 5.2 Nonlinear SVM (RBF) / kNN

* 上記+ RankGauss or RobustScaler（外れ値耐性）で性能改善を狙う。 ([UBC CS][6], [Bradley Boehmke][4])

### 5.3 Tree Boosting (LightGBM / XGBoost)

* スケーリング不要。
* カテゴリは Label/Ordinal（ツリーが自動分割）で十分; 高カテゴリは頻度/Target エンコ試験。
* 欠損はそのまま（モデルが分岐で扱う）か、明示補完後欠損フラグ列追加。 ([GeeksforGeeks][10], [Stack Overflow][9], [UBC CS][6])

### 5.4 CatBoost

* **カテゴリ列をそのまま渡す**（テキスト→string型）。One-Hot事前実行は推奨されず品質低下の恐れ。Ordered Target Statisticsで自動変換。欠損はCatBoost側で処理可だが明示NaNで渡す。 ([catboost.ai][16], [neptune.ai][17], [Kaggle][18])

---

## 6. 推奨ワークフロー（実装順）

1. **Raw Load & Audit**: 列一覧・dtype・欠損率・ユニーク値を出力する `audit_data.py`（repo scripts/）。 ([opendatabay.com][1], [Medium][2])
2. **Value Normalization Map**: Yes/No変換辞書・頻度カテゴリ順序マスタ（YAML管理）。 ([Medium][7], [scikit-learn.org][8])
3. **Fold-safe Preprocessing Pipeline**: scikit-learn ColumnTransformer + Pipeline で欠損→エンコ→スケールをFold内fit。 ([Medium][11], [UBC CS][6])
4. **Stratified CV Runner**: n\_splits=10 (例)、shuffle=True, random\_state固定。 ([GeeksforGeeks][12], [MachineLearningMastery.com][13])
5. **Model Zoo**: Logistic / CatBoost / LGBM / XGB を共通インタフェースで回しOOF比較。CatBoostのみ専用データハンドラ（カテゴリ列文字列渡し）で別Pipeline。 ([catboost.ai][16], [neptune.ai][17], [Medium][11])
6. **Noise & Interaction Feats Experiment Branch**: 開発ブランチで追加派生特徴→CV影響を記録。 ([Bradley Boehmke][4], [GeeksforGeeks][10])

---

## 7. 実装チェックリスト（コピー用）

* [ ] 生データ読込 & dtype設定
* [ ] 基本統計レポート（欠損率, ユニークカテゴリ, 数値範囲）
* [ ] Yes/No正規化・カテゴリ標準化辞書作成
* [ ] 順序カテゴリマスタ定義（低→高頻度／行動レベル）
* [ ] 欠損インピュタ（数値=中央値 / カテゴリ=最頻 or “Unknown”）
* [ ] Fold内fit Pipeline（trainのみで学習→val transform）
* [ ] Stratified K-Fold CV設定
* [ ] モデルファミリ別前処理適用
* [ ] 外れ値クリップ（任意）
* [ ] 追加特徴（比率・相互作用）実験
* [ ] 元データ突き合わせラベル監査（任意）

（上記タスクに優先度タグを付けてGitHub Issues化可。） ([Medium][11], [GeeksforGeeks][12], [Kaggle][15])

---

## 8. 次アクション提案

以下のいずれかを選択ください。
**A.** 上記チェックリストを `CLAUDE.md` / `README_preprocess.md` に追記するPR用Markdownを生成。
**B.** scikit-learn `make_preprocess_pipeline()` 実装（数値/カテゴリ自動推論, Yes/Noマッピング, Ordinal辞書入力）。
**C.** CatBoost専用 `data_prep_catboost()` 関数（カテゴリ列キャスト & 欠損保持）。
**D.** データ監査ノートブック（EDA + 欠損可視化 + 型チェック）を自動生成。

ご希望のオプション（複数可）と、列名の実際の値（train.csvのヘッダ）をお知らせください。すぐにコード／ドキュメント化いたします。

---

### 参考情報（出典一覧）

* Opendatabay「Extrovert and Introvert Personality Traits Dataset」列定義・欠損記載。 ([opendatabay.com][1])
* Medium「Building a Personality Detector App — Part 1: Model Training」行動特徴リスト・前処理(encoding, balancing)項目。 ([Medium][2])
* Kaggle S5E7 Dataページ（Playground用シンセティック生成）。 ([Kaggle][3])
* UBC CPSC330 Preprocessing講義（欠損・スケーリング・One-Hot）。 ([UBC CS][6])
* IBM Feature Engineering概説（欠損補完・外れ値対処・反復的FE）。 ([IBM][5])
* HOML (Boehmke) Feature/Target Engineering（データ理解・前処理重要性）。 ([Bradley Boehmke][4])
* Medium「PREPROCESSING OUR DATA: PART 2」（Yes/No→0/1, 欠損処理）。 ([Medium][7])
* scikit-learn OrdinalEncoder API（順序カテゴリ整数化）。 ([scikit-learn.org][8])
* StackOverflow「How to handle categorical data…」（順序設定・リーク注意・Pipeline内変換）。 ([Stack Overflow][9])
* GeeksforGeeks Stratified K-Fold解説（不均衡データ対策）。 ([GeeksforGeeks][12])
* MachineLearningMastery Stratified CV for Imbalanced Classification（クラス分布保持の重要性）。 ([MachineLearningMastery.com][13])
* Medium「Comprehensive Guide to Stratified K-Fold」（不均衡時の信頼性向上）。 ([Medium][14])
* CatBoost公式Docs（One-Hot事前処理非推奨; 自動カテゴリ変換）。 ([catboost.ai][16])
* Neptune.ai「When to Choose CatBoost…」（Ordered Target Stats, 自動カテゴリ処理）。 ([neptune.ai][17])
* Kaggle Q\&A「How does Catboost handle the data?」（Ordered Target Encoding, Missing対応）。 ([Kaggle][18])
* Kaggle Discussion S5E7 588644（元データ行一致・ラベル確認コード）。 ([Kaggle][15])

---

ご希望の実装プラン（A/B/C/D）をご指定ください。また、実際の `train.csv` から列名・カテゴリ値一覧（先頭数行でも可）をご共有いただければ、即座に前処理コードを生成します。

[1]: https://www.opendatabay.com/data/dataset/38f5db6d-f707-46ad-8edc-578b44dc73e0 "Extrovert and Introvert Personality Traits ... | Opendatabay"
[2]: https://medium.com/%40gayani.parameswaran/building-a-personality-detector-app-part-1-model-training-a31f50ed74f3 "Building a Personality Detector App — Part 1: Model Training | by Gayani Parameswaran | Jun, 2025 | Medium"
[3]: https://www.kaggle.com/competitions/playground-series-s5e7/data "Predict the Introverts from the Extroverts | Kaggle"
[4]: https://bradleyboehmke.github.io/HOML/engineering.html "Chapter 3 Feature & Target Engineering | Hands-On Machine Learning with R"
[5]: https://www.ibm.com/think/topics/feature-engineering "What is a feature engineering? | IBM"
[6]: https://ubc-cs.github.io/cpsc330-2024W2/lectures/notes/05_preprocessing-pipelines.html "Lecture 5: Preprocessing and sklearn pipelines — CPSC 330 Applied Machine Learning 2024W1"
[7]: https://ruhelalakshya.medium.com/preprocessing-our-data-part-2-ae4407c9c217 "PREPROCESSING OUR DATA : PART 2. Let’s take a look at our data set once… | by lakshya ruhela | Medium"
[8]: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html "OrdinalEncoder — scikit-learn 1.7.1 documentation"
[9]: https://stackoverflow.com/questions/53478046/how-to-handle-categorical-data-for-preprocessing-in-machine-learning "python - How to handle categorical data for preprocessing in Machine Learning - Stack Overflow"
[10]: https://www.geeksforgeeks.org/machine-learning/feature-encoding-techniques-machine-learning/ "Feature Encoding Techniques - Machine Learning - GeeksforGeeks"
[11]: https://dilipkumar.medium.com/scikit-learns-preprocessing-pipelines-3e03dccba3df "scikit-learn’s preprocessing pipelines | by Dilip Kumar | May, 2025 | Medium"
[12]: https://www.geeksforgeeks.org/machine-learning/stratified-k-fold-cross-validation/ "Stratified K Fold Cross Validation - GeeksforGeeks"
[13]: https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/ "How to Fix k-Fold Cross-Validation for Imbalanced Classification - MachineLearningMastery.com"
[14]: https://medium.com/%40juanc.olamendy/a-comprehensive-guide-to-stratified-k-fold-cross-validation-for-unbalanced-data-014691060f17 "A Comprehensive Guide to Stratified K-Fold Cross-validation for Unbalanced Data | by Juan C Olamendy | Medium"
[15]: https://www.kaggle.com/competitions/playground-series-s5e7/discussion/588644 "Predict the Introverts from the Extroverts | Kaggle"
[16]: https://catboost.ai/docs/en/features/categorical-features "Categorical features | CatBoost"
[17]: https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm "When to Choose CatBoost Over XGBoost or LightGBM"
[18]: https://www.kaggle.com/questions-and-answers/553569 "How does Catboost handle the data? | Kaggle"
