# Playground Series S5E7 上位勢の欠損値処理手法まとめ

Kaggleの「Playground Series Season 5 Episode 7（Introverts vs Extroverts）」において、**上位参加者たちは欠損データを有効に活用・処理する工夫を凝らしていました**。特に、スコア向上に貢献したとされる手法を以下に分類し、それぞれについて **(1)対象列、(2)処理方法、(3)モデルとの相性、(4)公開スコアや順位に関する言及** を整理します。

## 欠損フラグ（インジケーター）付与による処理

* **対象列**: 主に**欠損率が高い重要特徴**に対して適用されています。例えば *Stage\_fear*（約10%欠損）や*Going\_outside*（約8%欠損）、*Post\_frequency*、*Drained\_after\_socializing* など、回答率の低いアンケート項目が該当します。上位解法ではこれらカラムごとに欠損の有無を示すフラグを追加していました。

* **処理方法**: **欠損値が存在するかどうかの二値フラグ列を新たに作成**します。具体的には、元の欠損値は何らかの埋め方（数値なら中央値や平均、カテゴリなら最頻値など）で暫定補完しつつ、同時に「その行で当該特徴量が欠損だったか」を示す新特徴量 (`is_missing` 等) を追加する手法です。こうすることでモデルに対し「本来欠損であった」という情報を明示的に提供できます。実際、ある参加者は**明示的な欠損インジケータの追加**を試みており、Kaggleのチュートリアルでも「適切な欠損フラグの追加はモデルのスコア改善に寄与しうる」とされています。

* **モデルとの相性**: **決定木ベースのモデル（LightGBMやXGBoostなど）**は欠損値をそのまま扱って分岐処理できるため、本来は単純な欠損であってもモデル側である程度対応可能です。しかし上位勢は、それでも**欠損フラグを加えることでモデルが欠損そのものを強い予測手がかり（シグナル）として扱える**ように工夫しています。特に欠損発生自体がターゲット（性格の内向/外向）と相関する場合、フラグ追加によりその相関をモデルが捉えやすくなります。一方、**線形モデルやディープラーニングモデル**ではNaNを直接扱えないため必須的に何らかの値への置換＋欠損指示変数の併用が有効です。この手法はモデルを問わず汎用的ですが、**CatBoost**のように**欠損を自動処理**できるモデルではフラグの効果は相対的に限定的とも言われます（CatBoostはデータ読み込み時に欠損値を内部処理しカテゴリ変数でも別値扱いできるため）。

* **公開スコア／順位**: 欠損フラグ付与そのものの効果量について明確に数値が示されたケースは多くありませんが、**Kaggle公式の解説**では「欠損フラグを追加することでスコアが向上する場合がある」旨が言及されています。上位参加者のコメントからも「欠損をそのまま扱うよりフラグで明示した方がモデル精度が上がるケースがある」と示唆されており、実践的なテクニックとして認識されています。実際このコンペでも、多くの上位ノートブックで欠損フラグの有無を検討する記述が見られました（CVスコア改善の具体的な数値は公開されていませんが、有用性が語られています）。

## 特定値への置換（単純な埋め戻し）による処理

* **対象列**: 欠損フラグ同様に、*Stage\_fear*や*Drained\_after\_socializing*といった**カテゴリ変数**（質問へのYes/Noや頻度回答など）の欠損、および*Post\_frequency*等の**数値変数**の欠損が主な対象です。上位勢はこれらのカラムごとに**代表値や特別な値で補完**する戦略を取っています。特に回答形式のカテゴリ項目は欠損自体を一つのカテゴリとして扱う（後述の“Missing”ラベル法）ケースと、最頻カテゴリで埋めるケースに分かれました。

* **処理方法**: **各特徴量ごとに決め打ちの値で埋める**方法です。カテゴリ変数では\*\*「欠損」というカテゴリーを新設**して埋めるか、もしくは**最頻値（モード）で補完**するのが一般的でした。たとえば*Stage\_fear*や*Drained\_after\_socializing*は**欠損を最頻カテゴリで置換**しています（多くの場合これら質問項目では「No」や中央値の選択肢が最頻だったため、それが欠損補完に使われています）。一部の解法ではカテゴリ欠損に文字列"Missing"等のダミー値を入れてモデルに認識させた例もあります（*Stage\_fear*の欠損を'Missing'というカテゴリ値で穴埋めしたという報告あり）。一方、数値変数の欠損については**平均値や中央値での補完**が多く、例えばある上位ノートブックでは全数値カラムを平均値で埋めています。極端な場合は-1や0といった**明らかに異質な数値を埋め値として使う\*\*こともありますが、本コンペではデータの分布上、不自然な外れ値を入れる必要はなく平均/中央値で十分だったようです。

* **モデルとの相性**: 単純補完は**全てのモデルで扱いやすいデータを作る**ための基本的処理です。**木系モデル**に対しては本来不要な場合もありますが、欠損を埋めてしまうことでモデルが欠損部分も他の値と同様に扱う＝**欠損の情報を消してしまうリスク**があります。実際、ある上位者は「欠損値そのものが持つ情報を失わせないよう、安易なimputation（補完）は避けるべき」と指摘しています。しかし、**線形モデルやディープラーニング**では欠損を残せないため、このような代表値補完＋（可能なら欠損フラグ併用）が不可欠です。また**複数のモデルをアンサンブル**する際は、全モデルで整合した入力が必要になるため、一部のモデルに合わせて統一的に補完する方針も取られました。実例として、**LightGBM・XGBoost・CatBoost・ロジスティック回帰を組み合わせたアンサンブル**では、ロジスティック回帰が欠損非対応なこともあり**全モデル共通で欠損を平均値補完**しています。CatBoostは数値欠損を内部処理できますが、カテゴリ欠損は明示的に補完または他値に置換する必要があり、上述のように'Missing'ラベルで対応するケースがありました。

* **公開スコア／順位**: 単純な代表値補完は**堅実なベースライン構築**に寄与し、上位勢もまず試している手法です。例えば前述のアンサンブル手法では**公開スコア0.973279**を達成しており、これはベースラインモデル（全問正解率）の水準に匹敵する高精度です。このスコアはおそらくリーダーボード上位圏内に入るもので、平均値補完＋多モデル融合の有効性を示しています。モード補完について単独でのスコア向上幅は不明ですが、欠損を埋めることで**データの一貫性が保たれ安定した学習**につながったことは確かです。特に大きな情報損失を招かない範囲での補完（例えば高コリレーションを活かした補完、後述）は安全策として上位陣も採用していました。

## モデルごとの欠損値処理の使い分け

* **LightGBM／XGBoost 等の決定木モデル**:  これらのモデルは**欠損値を直接扱い分け可能**です。分岐条件においてNAを一つのグループとして自動的に処理できるため、必ずしも事前に埋める必要はありません。実際、**上位勢の多くは数値欠損をそのままLightGBMやXGBoostに入力**し、モデルに欠損処理を任せています。その理由は「純粋に予測のためであれば、欠損であること自体が強いシグナルになり得る」からであり、**下手に補完するとそのシグナルを壊してしまう**という見解が示されています。一方で、これらモデルでも**欠損フラグや特殊値補完を組み合わせた方が精度が上がる場合もある**ため（データ分布や欠損の偏りによる）、上位陣は両アプローチを検証して最適解を選んでいます。

* **CatBoost モデル**: CatBoostも決定木ベースですが、**カテゴリ変数を含む欠損値処理に独自の機構**があります。数値の欠損は他のブースティング同様に自動処理され、カテゴリ欠損も`nan`を一つのカテゴリーとして扱うことが可能です。ただし、カテゴリーデータを前処理で数値エンコードする際には**欠損に特別な符号を割り当てておく必要**があります。上位参加者のコードを見ると、カテゴリ値を数値に変換する際「欠損時は特定のコード（例えば-1や既存にないID）を付与する」処理が組み込まれていました。これはCatBoostや他のモデルで一貫してカテゴリ欠損を扱うための工夫です。総じてCatBoostは欠損に強いため、上位勢も**CatBoostでは大きな欠損対策をせずそのまま学習**させているケースが見られます（他モデルと違い、欠損フラグ追加の効果が小さいとの声もありました）。

* **その他モデル（線形回帰・k近傍法・ニューラルネット等）**:  これらのモデルは**欠損値を直接扱えない**ため、**事前に完全なデータにする必要**があります。上位勢は主要な学習器として木系モデルを使っていましたが、例えばスタッキングのメタモデルにロジスティック回帰を用いる場合や、外部からk近傍法やニューラルネットを試す場合には、**欠損をすべて埋めたデータセットを用意**して対応しています。実際、ある上位のアンサンブルではロジスティック回帰を組み込むために全特徴で欠損補完を実施しました。また一部の参加者は**k-NNによる欠損値補完**（類似する近傍データから欠損を推定する手法）も試みていますが、複数特徴が絡むため精度向上に直結しなかったとの報告があります。ニューラルネットも欠損値対応が難しいため、上位勢は\*\*事前に欠損処理済みのデータ（補完＋必要ならフラグ追加）\*\*を用意してから学習させていました。

* **公開スコア／順位**: モデル別の欠損対応を調整することも上位勢の工夫ポイントでした。例えば**LightGBMとCatBoostを用いた上位解法**では、両者とも欠損対応が可能なため「補完しない方がCVが良い」ケースがあったと推測されます（欠損そのものを活かした分岐ができるため）。一方で**ロジスティック回帰などを含む解法**では「確実に欠損を埋めておいた方が安定して精度が出る」ため、そのようにデータ処理したと述べています。順位との関連で言えば、**シンプルなLightGBM単体モデル**でも欠損を適切に扱えば高いスコアを達成でき、上位に食い込むことができました。実際本コンペの公開トップ付近にはLightGBM単体で調整した解法も存在したようです（詳細なスコアは不明ですが、欠損値の適切な扱いが勝敗を分けた一因と考えられます）。

## 複数特徴を用いた欠損値の推定・補完（交差特徴による処理）

* **対象列**: **相関の強い特徴同士で一方に欠損がある場合**に、その欠損値を他の特徴から推定できるケースがありました。具体的には、本データでは各質問項目同士の相関が高く（多重共線性が極めて高い）、たとえば*Stage\_fear*が欠損でも他の質問（社交イベント出席頻度や一人時間など）からその人の傾向をほぼ推測できる状況でした。したがって*Stage\_fear*や*Going\_outside*など主要項目の欠損がある行が主な対象となり、**他の非欠損の特徴量を使ってその欠損値を補完する**試みがなされています。

* **処理方法**: **他の特徴との関係性を利用して欠損を推定・補完する**アプローチです。上位勢は大きく二つの方法を用いていました：（a）**機械学習モデルによる推定補完**と、（b）**ルールベースの補完**です。（a）の例としては、ある参加者が「まず欠損のないデータで対象特徴（例：Stage\_fear）の予測モデルを学習し、**そのモデルに欠損行を入力して欠損値を予測させる**」ことでデータを埋める手法を提案しています。これは**逐次的補完（Iterative Imputation）**とも呼ばれる手法で、全特徴を何度も回しながら欠損を埋めていくアルゴリズムとして実装可能です。一方（b）のルールベース補完では、**ドメイン知識や統計的関係に基づき条件分岐で値を埋める**ものです。例えば「社交的な活動頻度が極端に低く他の内向性指標が高い人は、おそらく*Stage\_fear*も高いだろう」といった推論で、Stage\_fearの欠損に値を入れる試みが見られました。実際あるノートブックでは*Stage\_fear*の欠損を埋めるために**関連する社交性の指標を条件分岐に用いるロジック**を実装しています。このように**交差する特徴量同士の関係を利用**して欠損を補完することで、データの情報量を極力損なわずに分析を進めることができます。

* **モデルとの相性**: この交差補完を行うことで、**最終的な学習モデルには欠損のない完全なデータ**を渡すことができます。特に線形モデルやディープラーニングでは有効な前処理となり、決定木モデルであっても\*\*「欠損」として扱うより推定値でも埋まっていた方が精度が良い**場合があります（これは欠損がランダムでなくターゲットと関連している場合、モデルが自力でその関連性を学習するのが難しいため、あらかじめ他特徴から埋めてしまった方が良いケースです）。本コンペでは幸い**特徴間の相関が非常に強かった**ため、「他の質問から欠損をほぼ完璧に言い当てることができた」と報告する上位参加者もいました。この場合、補完によってノイズがそれほど増えないため、LightGBMなどで欠損そのまま扱う場合と比べて情報量が増える利点があります。一方で、もし誤った推定で穴埋めするとモデルに誤情報を与えるリスクも伴うため、上位勢は**クロスバリデーション上で補完の有無を比較**し、過学習にならない範囲でこの手法を採用していました。総じて、交差特徴による欠損補完は**「データに潜む追加のヒントを活かす」先進的な前処理\*\*と言え、上位解法の特徴の一つとなっています。

* **公開スコア／順位**: 交差特徴を用いた補完は上位勢ならではの工夫であり、その効果は間接的にリーダーボード上にも現れています。例えば、あるディスカッションでは「特徴量の高い多重共線性により欠損値を完全に埋めることができ、従って欠損によるスコア低下はほぼ無視できた」と示唆されていました。これは裏を返せば、**欠損を放置したままでは得られないスコア向上を達成した**可能性を意味します。具体的なCVスコアの比較は公開されていませんが、欠損補完後のモデルでは安定して高い精度を示し、公開リーダーボード上位を占めたチームの一部はこのテクニックを用いたと推察されます。Kaggle上でも「逐次的な欠損値補完を行い**完全なデータセットで学習する**べき」とのアドバイスが投票で支持されており、301位の参加者からの提案であっても上位者が実践に移していた可能性があります。 上位入賞者の正式なソリューション共有は見当たりませんでしたが、ディスカッションやノートブックから読み取れる限り、**欠損値をただ埋めるのではなく積極的に「活用」する発想**（欠損そのものを特徴にしたり、他特徴から推定したり）がスコア差を生んだと言えるでしょう。

**参考資料**: 上記内容はKaggle上の公開ノートブックやディスカッション（例: Oscar Bocanegra氏のEDAノートブック、Richard Jana氏のコメント、その他参加者の共有コードなど）から抽出しました。
