"""
クロスバリデーション戦略・評価指標
- StratifiedKFold設定
- CVスコア計算・集計
- 学習履歴ログ機能
- データリーク防止チェック
"""

import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.model_selection import StratifiedKFold
from sklearn.pipeline import Pipeline

logger = logging.getLogger(__name__)


class CVStrategy:
    """Cross-validation strategy configuration"""

    def __init__(self, n_splits: int = 5, shuffle: bool = True, random_state: int = 42):
        """
        Initialize CV strategy

        Args:
            n_splits: Number of CV folds
            shuffle: Whether to shuffle data before splitting
            random_state: Random seed for reproducibility
        """
        self.n_splits = n_splits
        self.shuffle = shuffle
        self.random_state = random_state
        self.cv = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)

    def split(self, X: np.ndarray, y: np.ndarray) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        Generate CV splits

        Args:
            X: Feature matrix
            y: Target vector

        Returns:
            List of (train_idx, val_idx) tuples
        """
        return list(self.cv.split(X, y))

    def get_config(self) -> Dict[str, Any]:
        """Get CV configuration"""
        return {"n_splits": self.n_splits, "shuffle": self.shuffle, "random_state": self.random_state, "stratify": True}


def calculate_accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Calculate accuracy score"""
    return accuracy_score(y_true, y_pred)


def calculate_auc(y_true: np.ndarray, y_pred_proba: np.ndarray) -> float:
    """Calculate AUC-ROC score"""
    return roc_auc_score(y_true, y_pred_proba)


def calculate_prediction_distribution(predictions: np.ndarray) -> Dict[str, float]:
    """
    Calculate prediction distribution statistics

    Args:
        predictions: Binary predictions (0/1)

    Returns:
        Dictionary with distribution statistics
    """
    extrovert_ratio = np.mean(predictions == 1)
    introvert_ratio = np.mean(predictions == 0)

    return {
        "extrovert_ratio": extrovert_ratio,
        "introvert_ratio": introvert_ratio,
        "extrovert_count": int(np.sum(predictions == 1)),
        "introvert_count": int(np.sum(predictions == 0)),
        "total_predictions": len(predictions),
    }


def aggregate_cv_scores(fold_scores: List[float]) -> Dict[str, float]:
    """
    Aggregate CV scores across folds

    Args:
        fold_scores: List of scores from each fold

    Returns:
        Dictionary with aggregated statistics
    """
    return {
        "mean_score": float(np.mean(fold_scores)),
        "std_score": float(np.std(fold_scores)),
        "min_score": float(np.min(fold_scores)),
        "max_score": float(np.max(fold_scores)),
        "median_score": float(np.median(fold_scores)),
    }


def check_data_integrity(X: np.ndarray, y: np.ndarray) -> Dict[str, bool]:
    """
    Check data integrity and detect potential issues

    Args:
        X: Feature matrix
        y: Target vector

    Returns:
        Dictionary with integrity check results
    """
    checks = {
        "shape_consistent": X.shape[0] == y.shape[0],
        "no_missing_features": not np.isnan(X).any(),
        "no_infinite_features": not np.isinf(X).any(),
        "no_missing_targets": not np.isnan(y).any(),
        "binary_targets": set(np.unique(y)) == {0, 1},
        "sufficient_samples": len(y) >= 10,
        "balanced_classes": all(np.bincount(y.astype(int)) > 0),
    }

    return checks


def validate_cv_leakage_prevention(model, X: np.ndarray, y: np.ndarray, cv_strategy: CVStrategy) -> Dict[str, Any]:
    """
    Validate that CV implementation prevents data leakage
    
    Args:
        model: Model or Pipeline instance
        X: Feature matrix
        y: Target vector
        cv_strategy: CV strategy to validate
        
    Returns:
        Dictionary with leakage prevention validation results
    """
    validation_results = {
        "uses_pipeline": isinstance(model, Pipeline),
        "preprocessing_isolated": False,
        "cv_splits_valid": True,
        "no_future_data_access": True,
        "validation_passed": False
    }
    
    # Check if using Pipeline for preprocessing isolation
    if isinstance(model, Pipeline):
        validation_results["preprocessing_isolated"] = True
        logger.info("✅ Pipeline detected: Preprocessing isolation enforced")
    else:
        logger.warning("⚠️  No Pipeline detected: Manual preprocessing separation required")
    
    # Validate CV splits don't overlap
    cv_splits = cv_strategy.split(X, y)
    
    for fold_idx, (train_idx, val_idx) in enumerate(cv_splits):
        train_set = set(train_idx)
        val_set = set(val_idx)
        
        # Check for overlap between train and validation within same fold
        if train_set & val_set:
            validation_results["cv_splits_valid"] = False
            logger.error(f"❌ Fold {fold_idx}: Train/validation overlap detected")
            break
    
    # Final validation  
    validation_results["validation_passed"] = validation_results["cv_splits_valid"]
    
    if validation_results["validation_passed"]:
        logger.info("✅ Data leakage prevention validation passed")
    else:
        logger.error("❌ Data leakage prevention validation failed")
    
    return validation_results


def validate_target_distribution(y: np.ndarray) -> Dict[str, Any]:
    """
    Validate and analyze target distribution

    Args:
        y: Target vector

    Returns:
        Dictionary with target distribution analysis
    """
    unique_values = np.unique(y)
    value_counts = np.bincount(y.astype(int))

    return {
        "unique_values": unique_values.tolist(),
        "class_counts": value_counts.tolist(),
        "class_ratios": (value_counts / len(y)).tolist(),
        "is_binary": len(unique_values) == 2,
        "has_both_classes": all(count > 0 for count in value_counts),
    }


class CVLogger:
    """Cross-validation logging functionality"""

    def __init__(self, log_dir: str = "outputs/logs"):
        """
        Initialize CV logger

        Args:
            log_dir: Directory to save logs
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)

    def create_log_entry(
        self, model_type: str, cv_config: Dict[str, Any], fold_scores: List[float], training_time: float, **kwargs
    ) -> Dict[str, Any]:
        """
        Create a structured log entry

        Args:
            model_type: Type of model (e.g., 'LightGBM')
            cv_config: CV configuration
            fold_scores: Scores from each fold
            training_time: Total training time in seconds
            **kwargs: Additional metadata

        Returns:
            Structured log entry
        """
        aggregated_scores = aggregate_cv_scores(fold_scores)

        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "model_type": model_type,
            "cv_config": cv_config,
            "fold_scores": fold_scores,
            "training_time": training_time,
            **aggregated_scores,
            **kwargs,
        }

        return log_entry

    def save_json_log(self, log_entry: Dict[str, Any], filename: str = None) -> str:
        """
        Save log entry as JSON

        Args:
            log_entry: Log entry to save
            filename: Optional filename (auto-generated if None)

        Returns:
            Path to saved log file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"cv_log_{timestamp}.json"

        log_path = self.log_dir / filename

        with open(log_path, "w") as f:
            json.dump(log_entry, f, indent=2)

        logger.info(f"CV log saved to {log_path}")
        return str(log_path)

    def save_csv_log(self, cv_results: pd.DataFrame, filename: str = None) -> str:
        """
        Save CV results as CSV

        Args:
            cv_results: DataFrame with CV results
            filename: Optional filename (auto-generated if None)

        Returns:
            Path to saved CSV file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"cv_results_{timestamp}.csv"

        csv_path = self.log_dir / filename
        cv_results.to_csv(csv_path, index=False)

        logger.info(f"CV results saved to {csv_path}")
        return str(csv_path)


def save_cv_log(log_data: Dict[str, Any], filepath: str) -> None:
    """
    Convenience function to save CV log

    Args:
        log_data: Log data to save
        filepath: Path to save the log
    """
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    with open(filepath, "w") as f:
        json.dump(log_data, f, indent=2)


# CV configuration constants
CV_CONFIG: Dict[str, Any] = {"n_splits": 5, "shuffle": True, "random_state": 42}

# Default CV strategy instance
default_cv_strategy = CVStrategy(**CV_CONFIG)
